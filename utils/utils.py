import polars as pl
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import precision_recall_curve, average_precision_score, roc_auc_score, roc_curve
import requests
import scipy.stats as ss
import glob
import gzip
import re
import os
# import py3Dmol
# from Bio.PDB import PDBParser


set2_palette = sns.color_palette("Set2")
clinvar_category = ['1_Pathogenic', '2_Benign', '3_Conflicting', '4_VUS', '5_Others', '6_No_ClinVar']
clinvar_palette_clinvar = sns.color_palette("Set2")
clinvar_palette_clinvar[0], clinvar_palette_clinvar[1], clinvar_palette_clinvar[2], \
    clinvar_palette_clinvar[3], clinvar_palette_clinvar[4], clinvar_palette_clinvar[5], clinvar_palette_clinvar[7] = \
clinvar_palette_clinvar[1], clinvar_palette_clinvar[4], clinvar_palette_clinvar[3], \
    clinvar_palette_clinvar[2], clinvar_palette_clinvar[0], clinvar_palette_clinvar[7], clinvar_palette_clinvar[5]

clinvar_order_dict = {
    "original": ['Pathogenic', 'Likely pathogenic', 'Benign', 'Likely benign', 'Conflicting', 'VUS', 'Others'],
    "bio_descending": ['Pathogenic', 'Likely pathogenic', 'Conflicting', 'VUS', 'Likely benign', 'Benign', 'Others']
}

palette_dict = {
    "clinvar_clnsig_clean_oneperc": dict(
        zip(clinvar_category, clinvar_palette_clinvar[:7])
    ),
    "clinvar_clnsig_clean": {
        'Pathogenic': "#CA7682",
        'Benign': "#1D7AAB",
        'Conflicting': "#505050", #"grey", or lighter red "#E6B1B8"
        'VUS': "#A0A0A0", ## Pillar default
        'Others': "#E0E0E0"
    },
    "clinvar_clnsig_clean_pp_strict": {
        'PLP': "#CA7682",
        'BLB': "#1D7AAB",
        'Pathogenic': "#CA7682",
        'Likely pathogenic': "#E6B1B8",
        'Benign': "#1D7AAB",
        'Likely benign': "#63A1C4",
        'Conflicting': "#505050", #"grey", or lighter red "#E6B1B8"
        'VUS': "#A0A0A0", ## Pillar default
        'Others': "#E0E0E0"
    }
}

colors_custom = {
    "Pathogenic": "#CA7682",
    "Pathogenic*": "#CA7682",
    "Likely Pathogenic": "#E6B1B8",
    "Likely Pathogenic*": "#E6B1B8",
    "Likely pathogenic": "#E6B1B8",
    "Benign": "#1D7AAB",
    "Benign*": "#1D7AAB",
    "Uncertain significance": "#A0A0A0",
    "Combined LR is not <0.5 or >2": "#A0A0A0",
    "VUS": "#A0A0A0",
    "No Classification": "#A0A0A0",
    "Model not applied": "#A0A0A0",
    "Likely Benign": "#63A1C4",
    "Likely Benign*": "#63A1C4",
    "Likely benign": "#63A1C4",
    '-12': "#176082",  # deepest blue
    '-11': "#1D7AAB",  # deep steel blue
    '-10': "#4B91A6",  # medium steel blue
    '-9': "#63A1C4",   # sky blue
    '-8': "#7AB5D1",   # soft blue-gray
    '-7': "#99C8DC",   # light blue-gray
    '-6': "#B8DCE8",   # very light blue
    '-5': "#D0E8F0",   # icy pale blue
    '-4': "#E4F1F6",   # faint pale blue
    '-3': "#EDF6FA",   # hint of blue
    '-2': "#F4F9FC",   # nearly white blue
    '-1': "#F9FCFE",   # even paler blue
    '0': "#E0E0E0",    # true neutral
    '1': "#F7E4E7",    # very pale pink
    '2': "#F0D0D5",    # pale dusty pink
    '3': "#E6B1B8",    # blush pink
    '4': "#D68F99",    # dusty rose
    '5': "#CA7682",    # muted rose
    '6': "#B85C6B",    # deeper rose
    '7': "#A84957",    # muted wine
    '8': "#943744",    # rich berry red
    '9': "#7F2936",    # burgundy
    '10': "#671B28",   # dark wine red
    '11': "#520F1C",   # deeper red
    '12': "#3A060D",   # near black red
    'Pathogenic to Benign': "#CA7682",
    'Benign to Pathogenic': "#7AB5D1",
    'Pathogenic to Pathogenic': "#B85F6E",
    'Benign to Benign': "#5C9EBD",
    'Benign to Uncertain': "#6FA6C5",
    'Pathogenic to Uncertain': "#C27B87",
    'Benign to Conflicting': "#80B3CC",
    'Pathogenic to Conflicting': "#CC8A94",
    'Benign to No Evidence': "#92C1D6",
    'Pathogenic to No Evidence': "#D29AA3",
    'No evidence': "#E0E0E0",        # base gray
    'No Classification': "#A0A0A0",  # silver gray
    'Conflicting evidence': "grey"   # neutral gray
}


def plot_cat_count_perc(df, cat, title="", ax=None, palette="Dark2"):
    clin_counts = df[cat].value_counts().sort(cat)
    clin_counts = clin_counts.with_columns(
        (pl.col("count") / pl.col("count").sum() * 100).alias("percent")
    )
    clin_counts = clin_counts.to_pandas()

    if ax is None:
        _, ax = plt.subplots(1, 1, figsize=(6, img_hits_perc_df.shape[0]))
    sns.barplot(data=clin_counts,
               y=cat,
               x="count",
               hue=cat,
               palette=palette,
               ax=ax
    )
    # percentage annotations
    max_tot = clin_counts["count"].max()
    for idx, row in clin_counts.iterrows():
        ax.text(
            max_tot * 0.01,
            idx,
            f"{row['percent']:.1f}%",
            va="center",
            ha="left",
            fontweight="bold",
            fontsize=12,
            color="black"
        )
        ax.grid(alpha=.2, axis="x")
    return clin_counts
    

def plot_assay_hit_by_category(df, hit_col, cat_cols, title="", ax=None):
    """
    plot_assay_hit_by_category
    ==========================
    
    Create a paired horizontal bar chart that shows, for every category in
    `cat_cols`, both the **total number of observations** and the **number of
    positive hits** (as defined by `hit_col`).  The chart also annotates the
    hit-rate as a percentage.
    
    Parameters
    ----------
    df : polars.DataFrame
        Input table containing at least the columns listed in `cat_cols` and a
        boolean column indicating hits.
    hit_col : str
        Name of the boolean column that flags hits (e.g. `"is_hit"`).
    cat_cols : str or list[str]
        Column(s) that define the categorical grouping(s).  If a single string is
        supplied it is handled automatically.
    title : str, optional
        Title placed above the plot.
    ax : matplotlib.axes.Axes, optional
        Pre-existing axes to draw on.  If None, a new figure and axes are created.
    
    Returns
    -------
    polars.DataFrame
        A tidy frame with one row per category, containing:
            - the grouping key(s)
            - total_counts   : total observations in that category
            - hit_counts     : observations that were hits
            - hit_perc       : hit rate in percent (hit_counts / total_counts * 100)
    
    Example
    -------
    >>> plot_assay_hit_by_category(
    ...     df=my_data,
    ...     hit_col="is_hit",
    ...     cat_cols="clinvar_clnsig_clean",
    ...     title="Hit rate by ClinVar significance"
    ... )
    """
    # --- compute hit counts and percentages ---
    df_tot_cnt_per_cat = (
        df.group_by(cat_cols)
        .len()
        .rename({"len": "total_counts"})
    )
    df_hit_cnt_per_cat = (
        df.unique("gene_allele")
        .filter(pl.col(hit_col))
        .group_by(cat_cols)
        .len()
        .rename({"len": "hit_counts"})
    )

    img_hits_perc_df = (
        df_tot_cnt_per_cat.join(
            df_hit_cnt_per_cat,
            on=cat_cols,
            how="left"
        )
        .fill_null(0)
        .with_columns(
            (pl.col("hit_counts") / pl.col("total_counts") * 100).alias("hit_perc")
        )
        .sort(cat_cols)
    )

    # --- plotting ---
    if ax is None:
        _, ax = plt.subplots(1, 1, figsize=(6, img_hits_perc_df.shape[0]))

    plot_df = img_hits_perc_df.to_pandas()

    # total bars (blue)
    sns.barplot(
        data=plot_df,
        y=cat_cols if isinstance(cat_cols, str) else cat_cols[-1],
        x="total_counts",
        color="steelblue",
        label="Total count",
        ax=ax
    )

    # hit bars (red)
    sns.barplot(
        data=plot_df,
        y=cat_cols if isinstance(cat_cols, str) else cat_cols[-1],
        x="hit_counts",
        color="tomato",
        label="Hit count",
        ax=ax
    )

    ax.set_title(title)
    ax.grid(alpha=.2)

    # percentage annotations
    max_tot = plot_df["total_counts"].max()
    for idx, row in plot_df.iterrows():
        ax.text(
            row["hit_counts"] + max_tot * 0.01,
            idx,
            f"{row['hit_perc']:.1f}%",
            va="center",
            ha="left",
            fontweight="bold",
            fontsize=12,
            color="black"
        )

    return img_hits_perc_df


def compute_aubprc(auprc, prior):
    return (auprc*(1-prior))/((auprc*(1-prior)) + ((1-auprc)*prior))


def plot_auroc_curves(df_clinvar_w_scores, pos_label, methods, set2_palette=set2_palette):
    """
    For each method, plot the adjusted PR curve (with both balanced and monotonized adjustments)
    and compute the adjusted AUPRC via bootstrapping. Also perform pairwise significance testing 
    of the AUPRC across different RSA categories.
    
    Parameters
    ----------
    df_clinvar_w_scores : Polars DataFrame
        Input data including columns "clinvar_clnsig_clean", category and predictor scores.
    methods : list of str
        List of method names corresponding to score columns in the data.
    set2_palette : list of str
        List of colors (e.g., from a color palette) to use for different RSA categories.
    n_bootstrap : int, optional
        Number of bootstrap iterations for significance testing (default is 1000).
    random_state : int or None, optional
        Seed for reproducibility.
    
    Returns
    -------
    ap_results : dict
        Dictionary of adjusted AUPRC values and bootstrap distributions, structured as:
          { method: { category: {"AP": <adjusted AUPRC>, "boot_ap": <bootstrap array> } } }
    significance : dict
        Dictionary mapping each method to a DataFrame of pairwise p-values comparing AUPRC between categories.
    """
    fig, axes = plt.subplots(1, 1, figsize=(4, 4))
        
    ap_results = {}  # to store adjusted AUPRC and bootstrap distributions
    # significance = {}  # to store pairwise significance p-values per method
    
    for m_idx, met in enumerate(methods):
        ap_results[met] = {}
        # Filter data for current category and valid clinical labels.
        df_clin_per_method = df_clinvar_w_scores.filter(
            (pl.col("clinvar_clnsig_clean").is_in(["1_Pathogenic", "2_Benign"]))
        ).with_columns(
            (
                pl.when(pl.col("clinvar_clnsig_clean") == pos_label)
                .then(1)
                .otherwise(0)
            ).alias("clinvar_label")
        ).drop_nulls(subset=["clinvar_clnsig_clean", met])
        
        # Convert to pandas DataFrame.
        df_pd = df_clin_per_method.to_pandas()
        df_pd = df_pd[["clinvar_label", met]].dropna()
        # Convert clinvar_label to boolean.
        truth = df_pd["clinvar_label"].astype(bool)
        # Create a scores DataFrame (with one column).
        scores = df_pd[[met]]
        # Create the YogiROC2 object using the new YogiROC2() constructor.
        fpr, tpr, thresholds = roc_curve(truth, scores)
        # Get the performance table from the YogiROC2 object.
        auc_score = roc_auc_score(truth, scores)
        ap_results[met] = auc_score

        # Plot the adjusted PR curve.
        axes.plot(100 * fpr, 100 * tpr,
                label=f"{met}: {auc_score:.2f}",
                color=set2_palette[methods.index(met)])
        # Plot chance level as a horizontal dashed line.
        # axes[m_idx].axhline(y=100 * prior, color=set2_palette[plddt_cats.index(cat)], ls="--")
    # Customize the subplot.
    handles, labels = axes.get_legend_handles_labels()
    # order = [2,1,0] if "rsa" in category else [3,1,0,2]
    precision_label = "True Positive Rate (%)"
    # title = f"AUROC by {category}"
    
    axes.legend(loc="lower right",
                    title="Assay")
    axes.set_xlabel("False Positive Rate (%)")
    axes.set_ylabel(precision_label)
    axes.set_title("AUROC")
    axes.grid(alpha=0.2)
    plt.tight_layout()
    plt.show()
    # plt.subplots_adjust(wspace=0.04)
    
    return ap_results ## , sig_results_dict


def plot_gene_level_summary(assay_df, assay, xlim=None, cat="clinvar_clnsig_clean", palette=None, ax=None):
    gene_allele_cnts = assay_df.group_by(
        ["symbol"]
    ).len().rename(
        {"len": "total_counts_all"}
    ).sort("total_counts_all", descending=True)
    
    gene_allele_cat_cnts = assay_df.group_by(
        ["symbol", cat]
    ).len().rename(
        {"len": "total_counts"}
    )
    gene_allele_cat_hits = assay_df.filter(
        (pl.col(assay))
    ).group_by(
        ["symbol", cat]
    ).len().rename(
        {"len": "hit_counts"}
    )
    total_allele_hit_sum_df = gene_allele_cat_cnts.join(
        gene_allele_cat_hits,
        on=["symbol", cat],
        how="left"
    ).fill_null(0).with_columns(
        (pl.col("hit_counts") / pl.col("total_counts") * 100).alias("hit_perc")
    ).join(gene_allele_cnts, on="symbol").sort(
        "total_counts_all", "symbol", cat, 
        descending=[True, True, False]
    )
    genes_with_hits = total_allele_hit_sum_df.filter(pl.col("hit_perc")>0)["symbol"].unique()
    
    # Convert to pandas and sort
    total_allele_hit_sum_df = total_allele_hit_sum_df.to_pandas().reset_index(drop=True)
    n_genes = len(total_allele_hit_sum_df)
    
    # Add percentage labels
    # Get unique categories and their positions
    categories = total_allele_hit_sum_df[cat].unique()
    n_categories = len(categories)
    # Calculate bar positions for each category
    bar_height = 0.8 / n_categories  # Default seaborn bar height divided by number of categories
    
    # Dynamically scale figure size
    if ax is None:
        fig_height = n_genes * bar_height * n_categories / 2.5
        fig_width = 6  # Slightly wider to accommodate labels
        fig, ax = plt.subplots(figsize=(fig_width, fig_height))
        
    if palette is None:
        palette = "Set2"
        
    # Create the barplots
    # Total counts (background bars)
    sns.barplot(
        data=total_allele_hit_sum_df, 
        y="symbol", 
        x="total_counts", 
        hue=cat,  # "clinvar_clnsig_clean"
        palette=palette,
        alpha=0.4,  # Make background bars slightly transparent
        ax=ax,
        # gap=.1,
        order=total_allele_hit_sum_df["symbol"].drop_duplicates(),
    )
    # Hit counts (foreground bars)
    sns.barplot(
        data=total_allele_hit_sum_df, 
        y="symbol", 
        x="hit_counts", 
        hue=cat,#"clinvar_clnsig_clean", 
        palette=palette,
        ax=ax,
        # gap=.1,
        order=total_allele_hit_sum_df["symbol"].drop_duplicates()
    )
    for i, gene in enumerate(total_allele_hit_sum_df["symbol"].unique()):
        gene_data = total_allele_hit_sum_df[total_allele_hit_sum_df["symbol"] == gene]
        for j, category in enumerate(categories):
            cat_data = gene_data[gene_data[cat] == category]
            if not cat_data.empty:
                # Calculate bar position
                bar_center = i + (j - (n_categories - 1) / 2) * bar_height
                # Get the hit percentage value
                hit_perc = cat_data["hit_perc"].iloc[0]
                hit_counts = cat_data["hit_counts"].iloc[0]
                # Add percentage label at the end of the hit_counts bar
                ax.text(
                    hit_counts + max(total_allele_hit_sum_df["hit_counts"]) * 0.01,  # Small offset
                    bar_center,
                    f"{hit_perc:.1f}%",
                    ha="left",
                    va="center",
                    fontsize=9 if n_genes > 20 else 10,
                    fontweight="bold"
                )
    
    # # Formatting
    ax.grid(alpha=0.2, axis='x')
    ax.set_xlabel("Count", fontsize=11)
    ax.set_ylabel("Gene Symbol", fontsize=11)
    ax.set_title(f"{assay}", fontsize=13)
    
    # Improve legend
    handles, labels = ax.get_legend_handles_labels()
    # Remove duplicate legend entries (seaborn creates duplicates with multiple barplots)
    unique_labels = []
    unique_handles = []
    for handle, label in zip(handles, labels):
        if label not in unique_labels:
            unique_labels.append(label)
            unique_handles.append(handle)
    
    ax.legend(unique_handles, unique_labels, 
              title=cat, 
              fontsize=10, 
              loc="lower right",
              framealpha=0.9)
    if xlim:
        ax.set_xlim(xlim)
        
    # plt.tight_layout()
    # plt.show()
    
    return total_allele_hit_sum_df


def get_uniprot_swissprot_id(protein_name: str) -> str:
    """
    Query UniProt’s REST search API to find the reviewed (Swiss‐Prot) accession
    for a given human gene/protein name. Returns None if not found.
    """
    url = "https://rest.uniprot.org/uniprotkb/search"
    # Build a query that:
    #  - matches the gene name exactly (using “gene:”)
    #  - restricts to human (organism_id:9606)
    #  - restricts to reviewed (Swiss‐Prot) entries
    query = f"gene:{protein_name} AND organism_id:9606 AND reviewed:true"
    params = {
        "query": query,
        "fields": "accession",
        "format": "json",
        "size": 1,      # only need the top hit
    }
    try:
        resp = requests.get(url, params=params, timeout=10)
        resp.raise_for_status()
        data = resp.json()
        results = data.get("results", [])
        if not results:
            return None
        return results[0]["primaryAccession"]
    except Exception:
        # If the request fails (e.g. no internet), return None
        return None
    

def rank_int_array(array: np.ndarray,
                   c: float = 3.0 / 8,
                   stochastic: bool = True,
                   seed: int = 0):
    '''
    Perform rank-based inverse normal transformation in a 1d numpy array. If
    stochastic is True ties are given rank randomly, otherwise ties will share
    the same value.

    Copied directly from: https://github.com/carpenter-singh-lab/2023_Arevalo_NatComm_BatchCorrection/blob/cd9bcf99240880a5c9f9858debf70e94f5b4c0f7/preprocessing/transform.py#L8
    Adapted from: https://github.com/edm1/rank-based-INT/blob/85cb37bb8e0d9e71bb9e8f801fd7369995b8aee7/rank_based_inverse_normal_transformation.py
    '''
    rng = np.random.default_rng(seed=seed)

    if stochastic:
        # Shuffle
        ix = rng.permutation(len(array))
        rev_ix = np.argsort(ix)
        array = array[ix]
        # Get rank, ties are determined by their position(hence why we shuffle)
        rank = ss.rankdata(array, method="ordinal")
        rank = rank[rev_ix]
    else:
        # Get rank, ties are averaged
        rank = ss.rankdata(array, method="average")

    x = (rank - c) / (len(rank) - 2 * c + 1)
    return ss.norm.ppf(x)
    

def inverse_normal_transform(data, feat_cols=None, c: float = 3.0 / 8, stochastic: bool = True, seed: int = 0):
    """
    Apply inverse normal transformation (rank-based normalization) to data using rank_int_array.
    
    Parameters:
    -----------
    data : polars.DataFrame
       Input dataframe
    feat_cols : list, optional
       Specific columns to transform. If None, auto-detect numeric columns
    c : float
       Blom's constant for rank transformation
    stochastic : bool
       Whether to use stochastic tie-breaking
    seed : int
       Random seed for stochastic tie-breaking
    """
    from tqdm.contrib.concurrent import thread_map
    import scipy.stats as ss
    
    # Determine columns to transform
    if feat_cols is not None:
        numeric_cols = feat_cols
    else:
        numeric_cols = [col for col in data.columns if "Meta" not in col]
    
    if not numeric_cols:
        return data  # No columns to transform
    
    # Convert to numpy for processing
    data_np = data.select(numeric_cols).to_numpy()
    
    def to_normal(i):
        """Transform column i using rank_int_array"""
        col_data = data_np[:, i].copy()  # Work on copy to avoid race conditions
        mask = ~np.isnan(col_data)
        
        if np.sum(mask) > 0:  # Only transform if there are non-null values
            # Transform non-null values
            transformed_values = rank_int_array(
               col_data[mask], 
               c=c, 
               stochastic=stochastic, 
               seed=seed + i  # Different seed per column for stochastic mode
            ).astype(np.float32)
            
            # Put transformed values back
            col_data[mask] = transformed_values
            data_np[:, i] = col_data
    
    # Apply transformation to all columns in parallel
    thread_map(to_normal, range(len(numeric_cols)), leave=False)
    
    # Convert back to polars DataFrame
    transformed_df = pl.DataFrame(
       data_np, 
       schema={col: pl.Float32 for col in numeric_cols}
    )
    
    # Combine with non-numeric columns if they exist
    non_numeric_cols = [col for col in data.columns if col not in numeric_cols]
    
    if non_numeric_cols:
        # Preserve original column order
        result_df = data.select(non_numeric_cols).hstack(transformed_df)
        return result_df.select(data.columns)  # Maintain original column order
    else:
        return transformed_df